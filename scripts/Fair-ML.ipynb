{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/grad/khern045/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>LSAT</th>\n",
       "      <th>UGPA</th>\n",
       "      <th>region_first</th>\n",
       "      <th>ZFYA</th>\n",
       "      <th>sander_index</th>\n",
       "      <th>first_pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>GL</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.782738</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>White</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>MS</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.670238</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.697024</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>GL</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>0.786310</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      race  sex  LSAT  UGPA region_first  ZFYA  sander_index   \n",
       "0           0     White    1  39.0   3.1           GL -0.98      0.782738  \\\n",
       "1           1     White    1  36.0   3.0           GL  0.09      0.735714   \n",
       "2           2     White    2  30.0   3.1           MS -0.35      0.670238   \n",
       "3           5  Hispanic    2  39.0   2.2           NE  0.58      0.697024   \n",
       "4           6     White    1  37.0   3.4           GL -1.26      0.786310   \n",
       "\n",
       "   first_pf  \n",
       "0       1.0  \n",
       "1       1.0  \n",
       "2       1.0  \n",
       "3       1.0  \n",
       "4       1.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = 'Fair-ML-Causal-Inference'\n",
    "law_path = os.path.join('~', base_path, 'data', 'law_data.csv')\n",
    "data = pd.read_csv(law_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data['region_first'].value_counts())\n",
    "data = data.loc[data['region_first'] != 'PO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21790 entries, 0 to 21790\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   race    21790 non-null  object \n",
      " 1   sex     21790 non-null  int64  \n",
      " 2   LSAT    21790 non-null  float64\n",
      " 3   UGPA    21790 non-null  float64\n",
      " 4   ZFYA    21790 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 1021.4+ KB\n"
     ]
    }
   ],
   "source": [
    "cols_keep = ['race', 'sex', 'LSAT', 'UGPA', 'ZFYA'] \n",
    "law_data = data[cols_keep]\n",
    "law_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "White          18284\n",
       "Black           1282\n",
       "Asian            845\n",
       "Hispanic         488\n",
       "Mexican          389\n",
       "Other            293\n",
       "Puertorican      110\n",
       "Amerindian        99\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sex\n",
       "2    12253\n",
       "1     9537\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the distributions for our OHE data\n",
    "display(law_data['race'].value_counts(), law_data['sex'].value_counts())\n",
    "\n",
    "# convert sex to category\n",
    "law_data.loc[:,'sex'] = np.where(law_data['sex'] == 1, 'Female', 'Male')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/grad/khern045/.local/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/accounts/grad/khern045/.local/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# split the data first to avoid data leakage\n",
    "train, test = train_test_split(law_data, train_size=0.8, random_state=256)\n",
    "\n",
    "# explicity categories and their unique values\n",
    "categories = [('sex', list(law_data['sex'].unique())),\n",
    "              ('race', list(law_data['race'].unique()))]\n",
    "\n",
    "ohe_columns = [x[0] for x in categories]\n",
    "ohe_categories = [x[1] for x in categories]\n",
    "\n",
    "# initialize OHE\n",
    "enc = OneHotEncoder(sparse=False, categories=ohe_categories, )\n",
    "\n",
    "# fit and transform the train\n",
    "train_trans = pd.DataFrame(\n",
    "    enc.fit_transform(train[ohe_columns]),\n",
    "    columns = enc.get_feature_names_out(),\n",
    "    index = train.index\n",
    ")\n",
    "# concatenate transformed cols with non transformed\n",
    "train_trans = pd.concat([train.drop(ohe_columns, axis=1), train_trans], axis=1).reset_index(drop=True)\n",
    "train_trans.columns = [col.split('_')[1] if '_' in col else col for col in train_trans.columns]\n",
    "\n",
    "\n",
    "# apply same transformation to test\n",
    "test_trans = pd.DataFrame(\n",
    "    enc.fit_transform(test[ohe_columns]),\n",
    "    columns = enc.get_feature_names_out(),\n",
    "    index = test.index\n",
    ")\n",
    "test_trans = pd.concat([test.drop(ohe_columns, axis=1) ,test_trans], axis=1).reset_index(drop=True)\n",
    "test_trans.columns = [col.split('_')[1] if '_' in col else col for col in test_trans.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = train_trans.shape[0]\n",
    "n_test = test_trans.shape[0]\n",
    "\n",
    "train_trans['LSAT'] = train_trans['LSAT'].round()\n",
    "test_trans['LSAT'] = test_trans['LSAT'].round()\n",
    "\n",
    "X_train, y_train = torch.tensor(train_trans.drop(['ZFYA'], axis=1).values, dtype=torch.float32), torch.tensor(train_trans['ZFYA'], dtype=torch.float32) \n",
    "X_test, y_test = torch.tensor(test_trans.drop(['ZFYA'], axis=1).values, dtype=torch.float32), torch.tensor(test_trans['ZFYA'], dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "     def __init__(self, dataframe):\n",
    "          self.dataframe = dataframe\n",
    "      \n",
    "     def __len__(self):\n",
    "          return self.dataframe.shape[0]\n",
    "     \n",
    "     def __getitem__(self, idx):\n",
    "          x = torch.tensor(self.dataframe.drop(['ZFYA'], axis=1).loc[idx,:].values, dtype=torch.float32)\n",
    "          y = torch.tensor(self.dataframe.loc[idx, 'ZFYA'], dtype=torch.float32)\n",
    "          return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class inherits form a class called nn.Module\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    # initialization method for new class\n",
    "    def __init__(self, input_size, output_size):\n",
    "        # first thing always do is call initialization method from the parent class, nn.module\n",
    "        super().__init__()\n",
    "\n",
    "        # fully connected linear layer\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # run the linear layer\n",
    "        output = self.fc1(x)\n",
    "\n",
    "        return output\n",
    "    \n",
    "# evaluate models performance\n",
    "def evaluate(model, X_train, y_test):\n",
    "    # Make predictions\n",
    "    with torch.no_grad(): # disable gradient computation\n",
    "        predictions = model(X_train).squeeze()\n",
    "\n",
    "    # Calculate RMSE\n",
    "    mse = torch.nn.functional.mse_loss(predictions, y_test)\n",
    "    rmse = np.sqrt(mse.item())\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def train(network, train_dataset, test_dataset, file_name_model, n_epochs=10, batch_size = 25):\n",
    "    assert isinstance(file_name_model, str), \"The filename is not a string\"\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(Dataset(train_dataset), batch_size = batch_size, shuffle=True)\n",
    "    \n",
    "    X_test = torch.tensor(test_dataset.drop(['ZFYA'], axis=1).values, dtype=torch.float32)\n",
    "    y_test = torch.tensor(test_dataset['ZFYA'], dtype=torch.float32)\n",
    "    \n",
    "    # Move network to GPU if available\n",
    "    network = network.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters())\n",
    "\n",
    "    # best validation score initialization \n",
    "    validation_score_best = float('inf')\n",
    "    train_losses = []\n",
    "    validation_scores = []\n",
    "\n",
    "    # train loop\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in tqdm(data_loader, leave=False):\n",
    "            # unpack batch\n",
    "            X, y = batch\n",
    "\n",
    "            # zero parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward pass to get input\n",
    "            # output is of shape [20,1] but we want of size [20] to compare \n",
    "            output = network(X).squeeze()\n",
    "\n",
    "            # calculate loss\n",
    "            loss = nn.MSELoss()(output, y)\n",
    "            epoch_loss += loss.item()\n",
    "            # root_loss = torch.sqrt(loss)\n",
    "            \n",
    "            # backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step() # update model parameters\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / len(data_loader)  # Average loss per epoch\n",
    "        train_losses.append(avg_epoch_loss)  # Append average epoch loss\n",
    "        \n",
    "        validation_score = evaluate(network, X_test, y_test) # evaluation mode\n",
    "        validation_scores.append(validation_score)\n",
    "        if epoch % 5 == 0:\n",
    "            print(f'Epoch {epoch+1}, validation score: {validation_score}')\n",
    "        network.train() # back to train mode\n",
    "\n",
    "        if validation_score < validation_score_best:\n",
    "            validation_score_best = validation_score\n",
    "            torch.save(network.state_dict(), file_name_model+'.pt') \n",
    "            \n",
    "    print(f'Best validation score:{validation_score_best}')\n",
    "    return validation_scores, train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, validation score: 0.9341887489372261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, validation score: 0.8754007579756609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, validation score: 0.8718918706430719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation score:0.8716028547604374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# create and train model\n",
    "full_model = LinearRegressionModel(train_trans.shape[1]-1, 1)\n",
    "full_validation_scores, full_train_losses = train(full_model, train_trans, test_trans, 'full_model', n_epochs=15, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unaware Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, validation score: 0.9424677518999135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, validation score: 0.9147393092896225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, validation score: 0.9047014554912369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation score:0.9021603947086761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "protected_attributes = ['Female', 'Male', 'White', 'Hispanic', 'Asian', 'Black', 'Other', 'Mexican', 'Puertorican', 'Amerindian']\n",
    "\n",
    "train_unaware = train_trans.drop(protected_attributes, axis=1)\n",
    "test_unaware = test_trans.drop(protected_attributes, axis=1)\n",
    "\n",
    "unaware_model = LinearRegressionModel(train_unaware.shape[1]-1, 1)\n",
    "unaware_validation_scores, unaware_train_losses = train(unaware_model, train_unaware, test_unaware, 'unaware_model', n_epochs=15, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfair K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
