{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/grad/khern045/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>LSAT</th>\n",
       "      <th>UGPA</th>\n",
       "      <th>region_first</th>\n",
       "      <th>ZFYA</th>\n",
       "      <th>sander_index</th>\n",
       "      <th>first_pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>GL</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.782738</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>White</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>MS</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.670238</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.697024</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>GL</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>0.786310</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      race  sex  LSAT  UGPA region_first  ZFYA  sander_index   \n",
       "0           0     White    1  39.0   3.1           GL -0.98      0.782738  \\\n",
       "1           1     White    1  36.0   3.0           GL  0.09      0.735714   \n",
       "2           2     White    2  30.0   3.1           MS -0.35      0.670238   \n",
       "3           5  Hispanic    2  39.0   2.2           NE  0.58      0.697024   \n",
       "4           6     White    1  37.0   3.4           GL -1.26      0.786310   \n",
       "\n",
       "   first_pf  \n",
       "0       1.0  \n",
       "1       1.0  \n",
       "2       1.0  \n",
       "3       1.0  \n",
       "4       1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = 'Fair-ML-Causal-Inference'\n",
    "law_path = os.path.join('~', base_path, 'data', 'law_data.csv')\n",
    "data = pd.read_csv(law_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region_first\n",
       "NE    4302\n",
       "GL    3822\n",
       "FW    2904\n",
       "SE    2651\n",
       "MS    2346\n",
       "SC    2251\n",
       "Mt    1147\n",
       "NG    1133\n",
       "MW    1071\n",
       "NW     163\n",
       "PO       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data['region_first'].value_counts())\n",
    "data = data.loc[data['region_first'] != 'PO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21790 entries, 0 to 21790\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   race    21790 non-null  object \n",
      " 1   sex     21790 non-null  int64  \n",
      " 2   LSAT    21790 non-null  float64\n",
      " 3   UGPA    21790 non-null  float64\n",
      " 4   ZFYA    21790 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 1021.4+ KB\n"
     ]
    }
   ],
   "source": [
    "cols_keep = ['race', 'sex', 'LSAT', 'UGPA', 'ZFYA'] \n",
    "law_data = data[cols_keep]\n",
    "law_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "White          18284\n",
       "Black           1282\n",
       "Asian            845\n",
       "Hispanic         488\n",
       "Mexican          389\n",
       "Other            293\n",
       "Puertorican      110\n",
       "Amerindian        99\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sex\n",
       "2    12253\n",
       "1     9537\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the distributions for our OHE data\n",
    "display(law_data['race'].value_counts(), law_data['sex'].value_counts())\n",
    "\n",
    "# convert sex to category\n",
    "law_data.loc[:,'sex'] = np.where(law_data['sex'] == 1, 'Female', 'Male')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/grad/khern045/.local/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/accounts/grad/khern045/.local/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# split the data first to avoid data leakage\n",
    "train, test = train_test_split(law_data, train_size=0.8, random_state=256)\n",
    "\n",
    "# explicity categories and their unique values\n",
    "categories = [('sex', list(law_data['sex'].unique())),\n",
    "              ('race', list(law_data['race'].unique()))]\n",
    "\n",
    "ohe_columns = [x[0] for x in categories]\n",
    "ohe_categories = [x[1] for x in categories]\n",
    "\n",
    "# initialize OHE\n",
    "enc = OneHotEncoder(sparse=False, categories=ohe_categories, )\n",
    "\n",
    "# fit and transform the train\n",
    "train_trans = pd.DataFrame(\n",
    "    enc.fit_transform(train[ohe_columns]),\n",
    "    columns = enc.get_feature_names_out(),\n",
    "    index = train.index\n",
    ")\n",
    "# concatenate transformed cols with non transformed\n",
    "train_trans = pd.concat([train.drop(ohe_columns, axis=1), train_trans], axis=1).reset_index(drop=True)\n",
    "train_trans.columns = [col.split('_')[1] if '_' in col else col for col in train_trans.columns]\n",
    "\n",
    "\n",
    "# apply same transformation to test\n",
    "test_trans = pd.DataFrame(\n",
    "    enc.fit_transform(test[ohe_columns]),\n",
    "    columns = enc.get_feature_names_out(),\n",
    "    index = test.index\n",
    ")\n",
    "test_trans = pd.concat([test.drop(ohe_columns, axis=1) ,test_trans], axis=1).reset_index(drop=True)\n",
    "test_trans.columns = [col.split('_')[1] if '_' in col else col for col in test_trans.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = train_trans.shape[0]\n",
    "n_test = test_trans.shape[0]\n",
    "\n",
    "train_trans['LSAT'] = train_trans['LSAT'].round()\n",
    "test_trans['LSAT'] = test_trans['LSAT'].round()\n",
    "\n",
    "X_train, y_train = torch.tensor(train_trans.drop(['ZFYA'], axis=1).values, dtype=torch.float32), torch.tensor(train_trans['ZFYA'], dtype=torch.float32) \n",
    "X_test, y_test = torch.tensor(test_trans.drop(['ZFYA'], axis=1).values, dtype=torch.float32), torch.tensor(test_trans['ZFYA'], dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "     def __init__(self, dataframe):\n",
    "          self.dataframe = dataframe\n",
    "      \n",
    "     def __len__(self):\n",
    "          return self.dataframe.shape[0]\n",
    "     \n",
    "     def __getitem__(self, idx):\n",
    "          x = torch.tensor(self.dataframe.drop(['ZFYA'], axis=1).loc[idx,:].values, dtype=torch.float32)\n",
    "          y = torch.tensor(self.dataframe.loc[idx, 'ZFYA'], dtype=torch.float32)\n",
    "          return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class inherits form a class called nn.Module\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    # initialization method for new class\n",
    "    def __init__(self, input_size, output_size):\n",
    "        # first thing always do is call initialization method from the parent class, nn.module\n",
    "        super().__init__()\n",
    "\n",
    "        # fully connected linear layer\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # run the linear layer\n",
    "        output = self.fc1(x)\n",
    "\n",
    "        return output\n",
    "    \n",
    "# evaluate models performance\n",
    "def evaluate(model, X_train, y_test):\n",
    "    # Make predictions\n",
    "    with torch.no_grad(): # disable gradient computation\n",
    "        predictions = model(X_train).squeeze()\n",
    "\n",
    "    # Calculate RMSE\n",
    "    mse = torch.nn.functional.mse_loss(predictions, y_test)\n",
    "    rmse = np.sqrt(mse.item())\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def train(network, train_dataset, test_dataset, file_name_model, n_epochs=10, batch_size = 25):\n",
    "    assert isinstance(file_name_model, str), \"The filename is not a string\"\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(Dataset(train_dataset), batch_size = batch_size, shuffle=True)\n",
    "    \n",
    "    X_test = torch.tensor(test_dataset.drop(['ZFYA'], axis=1).values, dtype=torch.float32)\n",
    "    y_test = torch.tensor(test_dataset['ZFYA'], dtype=torch.float32)\n",
    "    \n",
    "    # Move network to GPU if available\n",
    "    network = network.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters())\n",
    "\n",
    "    # best validation score initialization \n",
    "    validation_score_best = float('inf')\n",
    "    train_losses = []\n",
    "    validation_scores = []\n",
    "\n",
    "    # train loop\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in tqdm(data_loader, leave=False):\n",
    "            # unpack batch\n",
    "            X, y = batch\n",
    "\n",
    "            # zero parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward pass to get input\n",
    "            # output is of shape [20,1] but we want of size [20] to compare \n",
    "            output = network(X).squeeze()\n",
    "\n",
    "            # calculate loss\n",
    "            loss = nn.MSELoss()(output, y)\n",
    "            epoch_loss += loss.item()\n",
    "            # root_loss = torch.sqrt(loss)\n",
    "            \n",
    "            # backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step() # update model parameters\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / len(data_loader)  # Average loss per epoch\n",
    "        train_losses.append(avg_epoch_loss)  # Append average epoch loss\n",
    "        \n",
    "        validation_score = evaluate(network, X_test, y_test) # evaluation mode\n",
    "        validation_scores.append(validation_score)\n",
    "        if epoch % 5 == 0:\n",
    "            print(f'Epoch {epoch+1}, validation score: {validation_score}')\n",
    "        network.train() # back to train mode\n",
    "\n",
    "        if validation_score < validation_score_best:\n",
    "            validation_score_best = validation_score\n",
    "            torch.save(network.state_dict(), file_name_model+'.pt') \n",
    "            \n",
    "    print(f'Best validation score:{validation_score_best}')\n",
    "    return validation_scores, train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and train model\n",
    "full_model = LinearRegressionModel(train_trans.shape[1]-1, 1)\n",
    "full_model.load_state_dict(torch.load('full_model.pt'))\n",
    "# full_validation_scores, full_train_losses = train(full_model, train_trans, test_trans, 'full_model', n_epochs=15, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unaware Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protected_attributes = ['Female', 'Male', 'White', 'Hispanic', 'Asian', 'Black', 'Other', 'Mexican', 'Puertorican', 'Amerindian']\n",
    "\n",
    "train_unaware = train_trans.drop(protected_attributes, axis=1)\n",
    "test_unaware = test_trans.drop(protected_attributes, axis=1)\n",
    "\n",
    "unaware_model = LinearRegressionModel(train_unaware.shape[1]-1, 1)\n",
    "unaware_model.load_state_dict(torch.load('unaware_model.pt'))\n",
    "# unaware_validation_scores, unaware_train_losses = train(unaware_model, train_unaware, test_unaware, 'unaware_model', n_epochs=15, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fair K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def FairKModel(R, S, GPA=None, LSAT=None, FYA=None, num_observations=None):\n",
    "    num_race_cats = len(law_data['race'].unique())\n",
    "    num_sex_cats = len(law_data['sex'].unique())    \n",
    "\n",
    "    # 0,1 vectors for the normal distribution\n",
    "    # R and S are matrices\n",
    "    r0_vec = torch.zeros(num_race_cats)\n",
    "    s0_vec = torch.zeros(num_sex_cats)\n",
    "    r1_vec = torch.ones(num_race_cats)\n",
    "    s1_vec = torch.ones(num_sex_cats)\n",
    "\n",
    "    # prior latent variable 'K' (knowledge)\n",
    "    K = pyro.sample('K', dist.Normal(torch.tensor(0.), torch.tensor(1.)))\n",
    "\n",
    "    # priors for weights and baselines for GPA, LSAT and FYA\n",
    "    # GPA ~ N(b_G  + w_G^K K + w_G^R R + w_G^S S, \\sigma_G)\n",
    "    b_G = pyro.sample('b_G', dist.Normal(torch.tensor(0.), torch.tensor(1.)))\n",
    "    w_G_K = pyro.sample('w_G_K', dist.Normal(torch.tensor(0.), torch.tensor(1.)))\n",
    "    w_G_R = pyro.sample('w_G_R', dist.Normal(r0_vec,r1_vec)) # outputs a vec of normals of len(race)\n",
    "    w_G_S = pyro.sample('w_G_S', dist.Normal(s0_vec,s1_vec)) # outputs a vec of normals of len(sex)\n",
    "    sigma_G = pyro.sample('sigma_G', dist.InverseGamma(torch.tensor(1.), torch.tensor(1.)))\n",
    "\n",
    "    # LSAT ~ Poisson(exp( b_L +w_L^K K + w_L^R R + w_L^S S))\n",
    "    b_L = pyro.sample('b_L', dist.Normal(torch.tensor(0.), torch.tensor(1.)))\n",
    "    w_L_K = pyro.sample('w_L_K', dist.Normal(torch.tensor(0.), torch.tensor(1.)))\n",
    "    w_L_R = pyro.sample('w_L_R', dist.Normal(r0_vec,r1_vec))\n",
    "    w_L_S = pyro.sample('w_L_S', dist.Normal(s0_vec,s1_vec))\n",
    "\n",
    "    # FYA ~ N(w_F^K K + w_F^R R + w_F^S S, 1)\n",
    "    w_F_K = pyro.sample('w_F_K', dist.Normal(torch.tensor(0.), torch.tensor(1.)))\n",
    "    w_F_R = pyro.sample('w_F_R', dist.Normal(r0_vec,r1_vec))\n",
    "    w_F_S = pyro.sample('w_F_S', dist.Normal(s0_vec,s1_vec))\n",
    "\n",
    "    # Calculate the parameters values of the data generating distributions\n",
    "    # print(len(b_G))\n",
    "    # print(len(w_G_K * K))\n",
    "    # print((torch.matmul(w_G_R, R.transpose(0,1))).shape)\n",
    "    # # w 1 x num_col_race\n",
    "    # # R len_race x num_col_race\n",
    "    # print((torch.matmul(w_G_S, S)).shape)\n",
    "\n",
    "    mu_G = b_G + w_G_K * K + torch.matmul(w_G_R, R.transpose(0,1)) + torch.matmul(w_G_S, S.transpose(0,1))\n",
    "    lambda_L = b_L + w_L_K * K + torch.matmul(w_L_R, R.transpose(0,1)) + torch.matmul(w_L_S, S.transpose(0,1))\n",
    "    mu_F = w_F_K * K + torch.matmul(w_F_R, R.transpose(0,1)) + torch.matmul(w_F_S, S.transpose(0,1))\n",
    "\n",
    "    # sample observed data\n",
    "    # pyro.plate is to denote independent observations and for vectorized computation\n",
    "    # use if dealing with multiple observations\n",
    "    with pyro.plate('data', num_observations):\n",
    "        # gives likelihood of observed data given model parameters\n",
    "        gpa = pyro.sample('gpa', dist.Normal(mu_G, sigma_G), obs=GPA) # obs is observed\n",
    "        lsat = pyro.sample('lsat', dist.Poisson(lambda_L.exp()), obs=LSAT)\n",
    "        fya = pyro.sample('fya', dist.Normal(mu_F, torch.tensor(1.)), obs=FYA)\n",
    "\n",
    "    return gpa, lsat, fya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1444pt\" height=\"367pt\"\n",
       " viewBox=\"0.00 0.00 1443.95 367.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 363)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-363 1439.95,-363 1439.95,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_data</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"594.95,-8 594.95,-83 812.95,-83 812.95,-8 594.95,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"788.95\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<!-- K -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>K</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"789.95\" cy=\"-235\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"789.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">K</text>\n",
       "</g>\n",
       "<!-- gpa -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>gpa</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" cx=\"630.95\" cy=\"-57\" rx=\"27.9\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"630.95\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">gpa</text>\n",
       "</g>\n",
       "<!-- K&#45;&gt;gpa -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>K&#45;&gt;gpa</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M789.75,-216.83C788.51,-190.52 782.3,-140.22 753.95,-111 725.95,-82.15 704.06,-100.65 667.95,-83 664.29,-81.21 660.58,-79.11 656.98,-76.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"658.68,-73.82 648.4,-71.26 654.84,-79.67 658.68,-73.82\"/>\n",
       "</g>\n",
       "<!-- lsat -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>lsat</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" cx=\"704.95\" cy=\"-57\" rx=\"27.9\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"704.95\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">lsat</text>\n",
       "</g>\n",
       "<!-- K&#45;&gt;lsat -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>K&#45;&gt;lsat</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M787.46,-216.72C783.36,-191.98 773.58,-145.65 753.95,-111 747.29,-99.25 737.55,-87.99 728.5,-78.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"730.78,-76.23 721.15,-71.81 725.92,-81.27 730.78,-76.23\"/>\n",
       "</g>\n",
       "<!-- fya -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>fya</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" cx=\"777.95\" cy=\"-57\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"777.95\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">fya</text>\n",
       "</g>\n",
       "<!-- K&#45;&gt;fya -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>K&#45;&gt;fya</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M788.77,-216.8C786.68,-186.1 782.29,-121.64 779.79,-84.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"783.28,-84.75 779.11,-75.01 776.29,-85.22 783.28,-84.75\"/>\n",
       "</g>\n",
       "<!-- b_G -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>b_G</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"246.95\" cy=\"-235\" rx=\"28.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"246.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">b_G</text>\n",
       "</g>\n",
       "<!-- b_G&#45;&gt;gpa -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>b_G&#45;&gt;gpa</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M246.73,-216.67C247.41,-189.67 252.97,-137.9 283.95,-111 329.52,-71.42 512.36,-61.36 592.73,-58.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"593.02,-62.33 602.91,-58.54 592.81,-55.33 593.02,-62.33\"/>\n",
       "</g>\n",
       "<!-- w_G_K -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>w_G_K</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"334.95\" cy=\"-235\" rx=\"41.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"334.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">w_G_K</text>\n",
       "</g>\n",
       "<!-- w_G_K&#45;&gt;gpa -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>w_G_K&#45;&gt;gpa</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M336.88,-216.76C340.84,-189.88 352.46,-138.27 384.95,-111 416.18,-84.78 532.7,-68.61 593.49,-61.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"593.9,-65.26 603.46,-60.69 593.13,-58.3 593.9,-65.26\"/>\n",
       "</g>\n",
       "<!-- w_G_R -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>w_G_R</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"435.95\" cy=\"-235\" rx=\"41.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"435.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">w_G_R</text>\n",
       "</g>\n",
       "<!-- w_G_R&#45;&gt;gpa -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>w_G_R&#45;&gt;gpa</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M438.42,-216.84C443.08,-190.56 455.59,-140.29 485.95,-111 515.45,-82.53 561.45,-69.16 593.71,-63.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"594.43,-66.44 603.67,-61.26 593.21,-59.55 594.43,-66.44\"/>\n",
       "</g>\n",
       "<!-- w_G_S -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>w_G_S</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"40.95\" cy=\"-235\" rx=\"40.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"40.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">w_G_S</text>\n",
       "</g>\n",
       "<!-- w_G_S&#45;&gt;gpa -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>w_G_S&#45;&gt;gpa</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.47,-216.75C45.88,-189.38 56.77,-136.51 90.95,-111 131.02,-81.08 476.23,-64.33 592.73,-59.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"593.11,-62.97 602.96,-59.07 592.82,-55.98 593.11,-62.97\"/>\n",
       "</g>\n",
       "<!-- sigma_G -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>sigma_G</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"149.95\" cy=\"-235\" rx=\"50.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">sigma_G</text>\n",
       "</g>\n",
       "<!-- sigma_G&#45;&gt;gpa -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>sigma_G&#45;&gt;gpa</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M152.84,-216.77C158.41,-189.44 173.39,-136.61 208.95,-111 269.89,-67.1 500.49,-59.5 592.6,-58.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"592.91,-61.73 602.87,-58.11 592.83,-54.73 592.91,-61.73\"/>\n",
       "</g>\n",
       "<!-- b_L -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>b_L</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"619.95\" cy=\"-235\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"619.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">b_L</text>\n",
       "</g>\n",
       "<!-- b_L&#45;&gt;lsat -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>b_L&#45;&gt;lsat</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M622.43,-216.72C626.54,-191.98 636.31,-145.65 655.95,-111 662.61,-99.25 672.35,-87.99 681.39,-78.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"683.98,-81.27 688.75,-71.81 679.12,-76.23 683.98,-81.27\"/>\n",
       "</g>\n",
       "<!-- w_L_K -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>w_L_K</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"704.95\" cy=\"-235\" rx=\"40.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"704.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">w_L_K</text>\n",
       "</g>\n",
       "<!-- w_L_K&#45;&gt;lsat -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>w_L_K&#45;&gt;lsat</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M704.95,-216.8C704.95,-186.23 704.95,-122.19 704.95,-85.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"708.45,-85.01 704.95,-75.01 701.45,-85.01 708.45,-85.01\"/>\n",
       "</g>\n",
       "<!-- w_L_R -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>w_L_R</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"874.95\" cy=\"-235\" rx=\"40.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"874.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">w_L_R</text>\n",
       "</g>\n",
       "<!-- w_L_R&#45;&gt;lsat -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>w_L_R&#45;&gt;lsat</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M872.73,-216.74C868.43,-190.32 856.53,-139.88 825.95,-111 797.33,-83.98 777.24,-100.4 741.95,-83 738.3,-81.2 734.59,-79.09 731,-76.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"732.7,-73.8 722.42,-71.23 728.86,-79.65 732.7,-73.8\"/>\n",
       "</g>\n",
       "<!-- w_L_S -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>w_L_S</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"534.95\" cy=\"-235\" rx=\"39.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"534.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">w_L_S</text>\n",
       "</g>\n",
       "<!-- w_L_S&#45;&gt;lsat -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>w_L_S&#45;&gt;lsat</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M537.17,-216.74C541.46,-190.32 553.36,-139.88 583.95,-111 612.56,-83.98 632.65,-100.4 667.95,-83 671.6,-81.2 675.31,-79.09 678.9,-76.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"681.04,-79.65 687.48,-71.23 677.2,-73.8 681.04,-79.65\"/>\n",
       "</g>\n",
       "<!-- w_F_K -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>w_F_K</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"1171.95\" cy=\"-235\" rx=\"40.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1171.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">w_F_K</text>\n",
       "</g>\n",
       "<!-- w_F_K&#45;&gt;fya -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>w_F_K&#45;&gt;fya</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1170.26,-216.97C1166.62,-189.9 1155.4,-137.44 1121.95,-111 1074.97,-73.87 894.57,-62.47 815.48,-59.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"815.14,-55.69 805.01,-58.8 814.87,-62.69 815.14,-55.69\"/>\n",
       "</g>\n",
       "<!-- w_F_R -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>w_F_R</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"973.95\" cy=\"-235\" rx=\"40.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"973.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">w_F_R</text>\n",
       "</g>\n",
       "<!-- w_F_R&#45;&gt;fya -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>w_F_R&#45;&gt;fya</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M971.48,-216.84C966.83,-190.54 954.33,-140.26 923.95,-111 893.89,-82.06 846.82,-68.74 814.29,-62.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"814.72,-59.26 804.28,-61.03 813.55,-66.16 814.72,-59.26\"/>\n",
       "</g>\n",
       "<!-- w_F_S -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>w_F_S</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"1072.95\" cy=\"-235\" rx=\"40.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1072.95\" y=\"-231.3\" font-family=\"Times,serif\" font-size=\"14.00\">w_F_S</text>\n",
       "</g>\n",
       "<!-- w_F_S&#45;&gt;fya -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>w_F_S&#45;&gt;fya</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1071.01,-216.76C1067.04,-189.89 1055.42,-138.29 1022.95,-111 991.75,-84.79 875.11,-68.56 814.71,-61.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"814.79,-58.23 804.47,-60.61 814.03,-65.19 814.79,-58.23\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-343.8\" font-family=\"Times,serif\" font-size=\"14.00\">K ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-328.8\" font-family=\"Times,serif\" font-size=\"14.00\">b_G ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-313.8\" font-family=\"Times,serif\" font-size=\"14.00\">w_G_K ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-298.8\" font-family=\"Times,serif\" font-size=\"14.00\">w_G_R ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-283.8\" font-family=\"Times,serif\" font-size=\"14.00\">w_G_S ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-268.8\" font-family=\"Times,serif\" font-size=\"14.00\">sigma_G ~ InverseGamma</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-253.8\" font-family=\"Times,serif\" font-size=\"14.00\">b_L ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-238.8\" font-family=\"Times,serif\" font-size=\"14.00\">w_L_K ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-223.8\" font-family=\"Times,serif\" font-size=\"14.00\">w_L_R ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-208.8\" font-family=\"Times,serif\" font-size=\"14.00\">w_L_S ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-193.8\" font-family=\"Times,serif\" font-size=\"14.00\">w_F_K ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">w_F_R ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-163.8\" font-family=\"Times,serif\" font-size=\"14.00\">w_F_S ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-148.8\" font-family=\"Times,serif\" font-size=\"14.00\">gpa ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-133.8\" font-family=\"Times,serif\" font-size=\"14.00\">lsat ~ Poisson</text>\n",
       "<text text-anchor=\"start\" x=\"1237.95\" y=\"-118.8\" font-family=\"Times,serif\" font-size=\"14.00\">fya ~ Normal</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f055df232d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor = torch.tensor(train_trans.values, dtype=torch.float32)\n",
    "model_graph = pyro.render_model(\n",
    "    FairKModel, \n",
    "    model_args=(train_tensor[:,5:], train_tensor[:,3:5], train_tensor[:,1], train_tensor[:,0], train_tensor[:,2], train_tensor.shape[0]),\n",
    "    render_distributions=True, \n",
    "    render_params=True\n",
    "    )\n",
    "model_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17432"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
